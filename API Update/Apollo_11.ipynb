{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Prompting with an Apollo 11 transcript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnQ_LVlzIeXo"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Apollo_11.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7QvXQMrIhuZ"
      },
      "source": [
        "This notebook provides a quick example of how to prompt Gemini using a text file. In this case, you'll use a 400 page transcript from [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLuL9m7KhvxR"
      },
      "outputs": [],
      "source": [
        "%pip install -U -q \"google-genai>=1.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "Download the transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4XeFdX1rxaE",
        "outputId": "bc1d456a-88c7-4dc3-ed3a-a68980090b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-07 04:09:45--  https://storage.googleapis.com/generativeai-downloads/data/a11.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.189.207, 142.250.152.207, 108.177.121.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.189.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 847790 (828K) [text/plain]\n",
            "Saving to: ‘a11.txt’\n",
            "\n",
            "\ra11.txt               0%[                    ]       0  --.-KB/s               \ra11.txt             100%[===================>] 827.92K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-04-07 04:09:45 (44.4 MB/s) - ‘a11.txt’ saved [847790/847790]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/data/a11.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoiKgO2CswzA"
      },
      "source": [
        "Upload the file using the File API so its easier to pass it to the model later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HzrDdp2Q1Cu",
        "outputId": "e0fa52ad-32a8-42ef-c6b4-7f13217bea0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/mn5ncipq3lhf\n"
          ]
        }
      ],
      "source": [
        "text_file_name = \"a11.txt\"\n",
        "print(f\"Uploading file...\")\n",
        "text_file = client.files.upload(file=text_file_name)\n",
        "print(f\"Completed upload: {text_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "## Generate Content\n",
        "\n",
        "After the file has been uploaded, you can make `client.models.generate_content` requests that reference the File API URI. Then you will ask the model to find a few lighthearted moments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b1d2fe3ea31",
        "outputId": "31f808d9-1a11-4745-914c-85bf08fc7407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are four lighthearted moments from the provided Apollo 11 transcript:\n",
            "\n",
            "1.  **00 00 05 35 CDR:** \"You sure sound clear down there, Bruce. Sounds like you're sitting in your living room.\"\n",
            "**00 00 05 39 CC:** \"Oh, thank you. You all are coming through beautifully, too.\"\n",
            "    *   This exchange is a friendly and relaxed acknowledgement of the good communication quality, creating a sense of ease and humor.\n",
            "\n",
            "2.  **00 00 08 34 CDR:** \"Well, it looks like a nice day for it. These thunderstorms down range is about all.\"\n",
            "    *   The commander lightheartedly comments on the weather, finding some humor in the fact that the only thing to note is some thunderstorms, considering they are on an Apollo mission.\n",
            "\n",
            "3.  **00 00 54 13 CMP:** \"And tell Glenn Parker down at the Cape that he lucked out.\"\n",
            "**00 00 54 17 CC:** \"Understand. Tell Glenn Parker he lucked out.\"\n",
            "**00 00 54 22 CMP:** \"Yes. He lucked out. He doesn't owe me a cup of coffee.\"\n",
            "**00 00 54 26 CC:** \"This is Houston. Roger. We'll pass it on.\"\n",
            "    *   This is a fun, personal message to someone on the ground, jokingly saying they don't owe a favor anymore, bringing a sense of humanity to the situation.\n",
            "\n",
            "4.  **00 02 53 03 CDR:** \"Hey, Houston, Apollo 11. That Saturn gave us a magnificent ride.\"\n",
            "**00 02 53 07 CC:** \"Roger, 11. We'll pass that on. And, it certainly looks like you are well on your way now.\"\n",
            "**00 02 53 30 CDR:** \"We have no complaints with any of the three stages on that ride. It was beautiful.\"\n",
            "**00 02 53 38 CC:** \"Roger. We copy. No transients at staging of any significance. Over.\"\n",
            "**00 02 53 44 CDR:** \"That's right. It was all - all a good ride.\"\n",
            "**00 02 53 47 CC:** \"Houston. Roger. Out.\"\n",
            "    *   This shows great satisfaction with the ride, using enthusiastic language to express how magnificent the journey has been so far.\n",
            "\n",
            "5. **00 01 29 27 LMP:** \"Cecil B. deAldrin is standing by for instructions.\"\n",
            "    * This name play on a famous movie director makes the mission more lighthearted by showing the crew member is having fun.\n",
            "\n",
            "6.  **00 03 00 0 LMP (TRANQ):** How do you read me now on OMNI A?\n",
            "**00 03 00 5 CC:** Okay. I say it was all good. Over.\n",
            "    *   Houston makes a typo. A good-natured ribbing over a relatively minor matter indicates a relaxed and jovial atmosphere.\n",
            "\n",
            "7.  **00 04 28 45 CMP:** \"I wanted to be 18 or 20 pounds above nominal, babe.\"\n",
            "**00 04 28 49 CC:** \"Sorry about that.\"\n",
            "    *   The response is casual and informal, indicating a light and amicable atmosphere between the crew and the Houston communicators.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Find four lighthearted moments in this text file.\"\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "response = client.models.generate_content(\n",
        "  model=f\"models/{MODEL_ID}\",\n",
        "  contents=[\n",
        "   prompt,\n",
        "   text_file\n",
        "  ],\n",
        "  config={\n",
        "   \"httpOptions\": {\"timeout\": 7200}\n",
        "  }\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPDYdQSKTg4"
      },
      "source": [
        "## Delete File\n",
        "\n",
        "Files are automatically deleted after 2 days or you can manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4eO8ZXoKdZf"
      },
      "outputs": [],
      "source": [
        "client.files.delete(name=text_file.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oUCqb6IUnH"
      },
      "source": [
        "## Learning more\n",
        "\n",
        "The File API accepts files under 2GB in size and can store up to 20GB of files per project. Learn more about the [File API](../quickstarts/File_API.ipynb) here."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}